{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f133843",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is prior probability? Give an example.\n",
    "\n",
    "Ans-1 Prior probability, in Bayesian statistics, is the probability of an event before new data is collected. \n",
    "\n",
    "Example- Example\n",
    "For example, three acres of land have the labels A, B, and C. One acre has reserves of oil below its surface, while the other two do not. The prior probability of oil being found on acre C is one third, or 0.333. But if a drilling test is conducted on acre B, and the results indicate that no oil is present at the location, then the posterior probability of oil being found on acres A and C become 0.5, as each acre has one out of two chances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What is posterior probability? Give an example.\n",
    "\n",
    "Ans-2 Posterior probability is a revised probability that takes into account new available information.\n",
    "\n",
    "For example, let there be two urns, urn A having 5 black balls and 10 red balls and urn B having 10 black balls and 5 red balls. Now if an urn is selected at random, the probability that urn A is chosen is 0.5. This is the a priori probability. \n",
    "If we are given an additional piece of information that a ball was drawn at random from the selected urn, and that ball was black, what is the probability that the chosen urn is urn A? Posterior probability takes into account this additional information and revises the probability downward from 0.5 to 0.333 according to Bayes´ theorem, because a black ball is more probable from urn B than urn A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What is likelihood probability? Give an example.\n",
    "\n",
    "Ans-3 Likelihood Function in Machine Learning and Data Science is the joint probability distribution(jpd) of the dataset given as a function of the parameter. Think of it as the probability of obtaining the observed data given the parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. What is Naïve Bayes classifier? Why is it named so?\n",
    "\n",
    "Ans-4 Naive Bayes classifiers are a collection of classification algorithms based on Bayes' Theorem. \n",
    "Naive Bayes is called naive because it assumes that each input variable is independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40583aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What is optimal Bayes classifier?\n",
    "\n",
    "Ans-5 Bayes Optimal Classifier is a probabilistic model that finds the most probable prediction using the training data and space of hypotheses to make a prediction for a new data instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Write any two features of Bayesian learning methods.\n",
    "\n",
    "Ans-6 Features of Bayesian learning methods:\n",
    "• Each observed training example can incrementally decrease or increase the estimated\n",
    "probability that a hypothesis is correct.\n",
    "   – This provides a more flexible approach to learning than algorithms that completely\n",
    "     eliminate a hypothesis if it is found to be inconsistent with any single example.\n",
    "\n",
    "        • Prior knowledge can be combined with observed data to determine the final\n",
    "probability of a hypothesis. In Bayesian learning, prior knowledge is provided by\n",
    "asserting \n",
    "\n",
    "   – a prior probability for each candidate hypothesis\n",
    "   – a probability distribution over observed data for each possible hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Define the concept of consistent learners.\n",
    "\n",
    "Ans-7 a learning algorithm is a consistent learner if it commits zero errors over the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8487e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Write any two strengths of Bayes classifier.\n",
    "\n",
    "Ans-8 two strengths of Bayes classifier are :-\n",
    "    \n",
    "1. This algorithm works quickly and can save a lot of time. \n",
    "\n",
    "2. Naive Bayes is suitable for solving multi-class prediction problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Write any two weaknesses of Bayes classifier.\n",
    "\n",
    "Ans-9 two weaknesses of Bayes classifier are :-\n",
    "    \n",
    "1. Naive Bayes assumes that all predictors (or features) are independent, rarely happening in real life. This limits the applicability of this algorithm in real-world use cases.\n",
    "\n",
    "2.This algorithm faces the ‘zero-frequency problem’ where it assigns zero probability to a categorical variable whose category in the test data set wasn’t available in the training dataset. It would be best if you used a smoothing technique to overcome this issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "1. Text classification\n",
    "\n",
    "2. Spam filtering\n",
    "\n",
    "3. Market sentiment analysis\n",
    "\n",
    "\n",
    "Ans-10 Navie Bayes Classifier is used for:\n",
    "\n",
    "1. Text classification: The Naive Bayes classifier is a simple classifier that classifies based on probabilities of events. It is the applied commonly to text classification. With the training set, we can train a Naive Bayes classifier which we can use to automaticall categorize a new sentence.\n",
    "\n",
    "2. Spam filtering: Naive Bayes classifiers work by correlating the use of tokens (typically words, or sometimes other things), with spam and non-spam e-mails and then using Bayes' theorem to calculate a probability that an email is or is not spam. It is one of the oldest ways of doing spam filtering, with roots in the 1990s.\n",
    "\n",
    "3. Market sentiment analysis: Market Sentiment analysis is a field dedicated to extracting subjective emotions and feelings from text. One common use of sentiment analysis is to figure out if a text expresses negative or positive feelings. Naive Bayes is a popular algorithm for classifying text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beace5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
